{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date, timedelta\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras import layers,Sequential,losses,optimizers,datasets\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class CorrelationLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(CorrelationLayer, self).__init__()\n",
    "\n",
    "    def call(self, x):\n",
    "        # Compute mean and standard deviation for each batch and node\n",
    "        mean = tf.reduce_mean(x, axis=1, keepdims=True)\n",
    "        std = tf.math.reduce_std(x, axis=1, keepdims=True)\n",
    "\n",
    "        # Compute centered inputs\n",
    "        x_centered = x - mean\n",
    "\n",
    "        # Compute covariance matrix for each batch and node\n",
    "        covariance_matrix = tf.matmul(x_centered, x_centered, transpose_b=True)\n",
    "\n",
    "        # Compute correlation matrix using covariance matrix and standard deviation\n",
    "        correlation_matrix = tf.divide(covariance_matrix, tf.matmul(std, std, transpose_b=True))\n",
    "\n",
    "        # Compute Laplacian transformation of correlation matrix\n",
    "        laplacian_transform = self.localpooling_filter(correlation_matrix)\n",
    "\n",
    "        return laplacian_transform\n",
    "\n",
    "    def localpooling_filter(self, matrix):\n",
    "        # Compute diagonal degree matrix\n",
    "        degree_matrix = tf.linalg.diag(tf.reduce_sum(matrix, axis=1))\n",
    "\n",
    "        # Compute graph Laplacian\n",
    "        laplacian_matrix = degree_matrix - matrix\n",
    "\n",
    "        # Compute Laplacian eigenvectors and eigenvalues\n",
    "        eigenvalues, eigenvectors = tf.linalg.eigh(laplacian_matrix)\n",
    "\n",
    "        # Compute Laplacian Fourier Transform\n",
    "        laplacian_transform = tf.matmul(eigenvectors, tf.matmul(tf.linalg.diag(eigenvalues), eigenvectors, adjoint_b=True))\n",
    "\n",
    "        return laplacian_transform\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORT SPEKTRAL CLASSES ###\n",
    "\n",
    "from spektral_utilities import *\n",
    "from spektral_gcn import GraphConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as scio\n",
    "import pandas as pd\n",
    "\n",
    "#input\n",
    "feature1 = r'\\Traning and Test\\ACC_EW.mat'\n",
    "data1 = scio.loadmat(feature1)\n",
    "AA=data1['ACC_EW']\n",
    "A=AA[:,0:300]\n",
    "\n",
    "feature2 = r'\\Traning and Test\\ACC_NS.mat'\n",
    "data2 = scio.loadmat(feature2)\n",
    "BB=data2['ACC_NS']\n",
    "B=BB[:,0:300]\n",
    "\n",
    "feature3 = r'\\Traning and Test\\ACC_UD.mat'\n",
    "data3 = scio.loadmat(feature3)\n",
    "CC=data3['ACC_UD']\n",
    "C=CC[:,0:300]\n",
    "\n",
    "feature4 = r'\\Traning and Test\\DIS_EW.mat'\n",
    "data4 = scio.loadmat(feature4)\n",
    "DD=data4['DIS_EW']\n",
    "D=DD[:,0:300]\n",
    "\n",
    "feature5 = r'\\Traning and Test\\DIS_NS.mat'\n",
    "data5 = scio.loadmat(feature5)\n",
    "EE=data5['DIS_NS']\n",
    "E=EE[:,0:300]\n",
    "\n",
    "feature6 = r'\\Traning and Test\\DIS_UD.mat'\n",
    "data6 = scio.loadmat(feature6)\n",
    "FF=data6['DIS_UD']\n",
    "F=FF[:,0:300]\n",
    "\n",
    "feature7 = r'\\Traning and Test\\VEL_EW.mat'\n",
    "data7 = scio.loadmat(feature7)\n",
    "GG=data7['VEL_EW']\n",
    "G=GG[:,0:300]\n",
    "\n",
    "feature8 = r'\\Traning and Test\\VEL_NS.mat'\n",
    "data8 = scio.loadmat(feature8)\n",
    "HH=data8['VEL_NS']\n",
    "H=HH[:,0:300]\n",
    "\n",
    "feature9 = r'\\Traning and Test\\VEL_UD.mat'\n",
    "data9 = scio.loadmat(feature9)\n",
    "II=data9['VEL_UD']\n",
    "I=II[:,0:300]\n",
    "\n",
    "\n",
    "label = pd.read_csv(open(r'\\KnowledgeBase\\PGA\\Features3s.csv',encoding='UTF-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18067, 2700)\n",
      "[-3.11349585 -1.6162357   0.39636245 -3.59711571  0.41005487 -2.31752914\n",
      "  2.41110903  0.37864947 -0.95081472  1.30721834  0.6623701 ]\n",
      "(18067, 11)\n"
     ]
    }
   ],
   "source": [
    "raw_data1=np.hstack((A,B))\n",
    "raw_data2=np.hstack((raw_data1,C))\n",
    "raw_data3=np.hstack((raw_data2,D))\n",
    "raw_data4=np.hstack((raw_data3,E))\n",
    "raw_data5=np.hstack((raw_data4,F))\n",
    "raw_data6=np.hstack((raw_data5,G))\n",
    "raw_data7=np.hstack((raw_data6,H))\n",
    "x_data=np.hstack((raw_data7,I))\n",
    "\n",
    "print(x_data.shape)\n",
    "\n",
    "\n",
    "y_data=label.iloc[:,[0,1,2,3,4,5,6,7,8,9,10]].values  #知识嵌入\n",
    "#y_data=label.iloc[:,[12]].values    #导入数据  iloc通过行号获取行数据\n",
    "print(y_data[0])\n",
    "print(y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练测试集\n",
    "#x_data_train_test=x_data[0:23432]\n",
    "#y_data_train_test=y_data[0:23432]\n",
    "#print(x_data_train_test.shape)\n",
    "#print(y_data_train_test.shape)\n",
    "#震例\n",
    "#x_data_zhenli=x_data[23432:27361]\n",
    "#y_data_zhenli=y_data[23432:27361]\n",
    "#print(x_data_zhenli.shape)\n",
    "#print(y_data_zhenli.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  #random_state=21  24  26  27  65\n",
    "train_xx, test_xx, train_y1, test_y1 = train_test_split(x_data, y_data, test_size=0.2, random_state=30)\n",
    "#print(train_xx.shape)   30 17.14  0.59\n",
    "#print(test_xx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14453, 1)\n",
      "[0.81624302]\n",
      "(14453, 9)\n",
      "[-2.86703925 -1.73043704  0.12188288 -2.9644417   0.31890487 -2.30641678\n",
      "  2.32117888  0.52351466 -0.73253894]\n",
      "(3614, 1)\n",
      "[0.97405023]\n",
      "(3614, 9)\n",
      "[-1.92127329 -1.0170204   0.6673474  -1.37351168  0.84724132 -1.34134927\n",
      "  2.84883262  1.36126256  0.32020884]\n"
     ]
    }
   ],
   "source": [
    "train_y=train_y1[:,[10]]\n",
    "train_physics=train_y1[:,[0,1,2,3,4,5,6,7,8]]\n",
    "print(train_y.shape)\n",
    "print(train_y[0])\n",
    "\n",
    "print(train_physics.shape)\n",
    "print(train_physics[0])\n",
    "\n",
    "\n",
    "\n",
    "test_y=test_y1[:,[10]]\n",
    "test_physics=test_y1[:,[0,1,2,3,4,5,6,7,8]]\n",
    "print(test_y.shape)\n",
    "print(test_y[0])\n",
    "\n",
    "print(test_physics.shape)\n",
    "print(test_physics[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=[]\n",
    "for i in range(len(train_xx)):\n",
    "    train_x.append(np.array(train_xx[i].reshape(9,1,300)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x=[]\n",
    "for i in range(len(test_xx)):\n",
    "    test_x.append(np.array(test_xx[i].reshape(9,1,300)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=np.array(train_x)\n",
    "test_x=np.array(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 14453\n",
      "1 300\n",
      "(14453, 300, 9)\n"
     ]
    }
   ],
   "source": [
    "#3#  ##Reshaping\n",
    "train_x = np.reshape(train_x, (train_x.shape[0], 300, 9))\n",
    "test_x = np.reshape(test_x, (test_x.shape[0], 300, 9))\n",
    "print(\"0\",train_x.shape[0])\n",
    "print(\"1\",train_x.shape[1])\n",
    "print(train_x.shape)\n",
    "#print(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "class Self_Attention(Layer):\n",
    " \n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(Self_Attention, self).__init__(**kwargs)\n",
    " \n",
    "    def build(self, input_shape):\n",
    "        # 为该层创建一个可训练的权重\n",
    "        #inputs.shape = (batch_size, time_steps, seq_len)\n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "                                      shape=(3,input_shape[2], self.output_dim),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    " \n",
    "        super(Self_Attention, self).build(input_shape)  # 一定要在最后调用它\n",
    " \n",
    "    def call(self, x):\n",
    "        WQ = K.dot(x, self.kernel[0])\n",
    "        WK = K.dot(x, self.kernel[1])\n",
    "        WV = K.dot(x, self.kernel[2])\n",
    " \n",
    "        print(\"WQ.shape\",WQ.shape)\n",
    " \n",
    "        print(\"K.permute_dimensions(WK, [0, 2, 1]).shape\",K.permute_dimensions(WK, [0, 2, 1]).shape)\n",
    " \n",
    " \n",
    "        QK = K.batch_dot(WQ,K.permute_dimensions(WK, [0, 2, 1]))\n",
    " \n",
    "        QK = QK / (64**0.5)\n",
    " \n",
    "        QK = K.softmax(QK)\n",
    " \n",
    "        print(\"QK.shape\",QK.shape)\n",
    " \n",
    "        V = K.batch_dot(QK,WV)\n",
    " \n",
    "        return V\n",
    " \n",
    "    def compute_output_shape(self, input_shape):\n",
    " \n",
    "        return (input_shape[0],input_shape[1],self.output_dim)\n",
    "\n",
    "    def get_config(self):  #在有自定义网络层时，需要保存模型时，重写get_config函数\n",
    "        config = {\"output_dim\": self.output_dim}\n",
    "        base_config = super(Self_Attention, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=50\n",
    "#50 17.20 1.32\n",
    "\n",
    "def get_model():\n",
    "\n",
    "    #opt = Adam(lr=0.001)\n",
    "\n",
    "    #inp_seq = tf.keras.layers.Input((sequence_length, 10))  #sequence_length = 14; 表示输入的序列长度是14; 14*10\n",
    "#    inp_lap = tf.keras.layers.Input((9, 9))  #输入的领接矩阵 10表示节点数\n",
    "    \n",
    "    inp = tf.keras.layers.Input((300,9))  #如果我用CNN提取特征？？  \n",
    "\n",
    "    feat = tf.keras.layers.Conv1D(32,kernel_size=4,strides=2,    #   32  15.76 0.65  33.68 0.302\n",
    "                  kernel_initializer=keras.initializers.he_normal(seed=seed),\\\n",
    "                  bias_initializer=keras.initializers.he_normal(seed=seed),\\\n",
    "                  input_shape = (300,9),padding=\"same\")(inp)\n",
    "    feat = tf.keras.layers.ReLU()(feat)\n",
    "    feat = tf.keras.layers.BatchNormalization()(feat) \n",
    "    feat = tf.keras.layers.MaxPooling1D(pool_size=2,strides=2,padding=\"same\")(feat)\n",
    "    feat = tf.keras.layers.Dropout(rate=0.2)(feat)  # \n",
    "    \n",
    "    \n",
    "    feat = tf.keras.layers.Conv1D(64,kernel_size=4,strides=2,   # 32  \n",
    "                  kernel_initializer=keras.initializers.he_normal(seed=seed),\\\n",
    "                  bias_initializer=keras.initializers.he_normal(seed=seed),\\\n",
    "                  padding=\"same\")(feat) \n",
    "    feat = tf.keras.layers.ReLU()(feat)\n",
    "    feat = tf.keras.layers.BatchNormalization()(feat) \n",
    "    feat = tf.keras.layers.MaxPooling1D(pool_size=2,strides=2,padding=\"same\")(feat) # 高宽各减半的池化层\n",
    "    feat = tf.keras.layers.Dropout(rate=0.2)(feat)  # \n",
    "    \n",
    "    feat = tf.keras.layers.Conv1D(128,kernel_size=4,strides=2,   # 32  \n",
    "                  kernel_initializer=keras.initializers.he_normal(seed=seed),\\\n",
    "                  bias_initializer=keras.initializers.he_normal(seed=seed),\\\n",
    "                  padding=\"same\")(feat) \n",
    "    feat = tf.keras.layers.ReLU()(feat)\n",
    "    feat = tf.keras.layers.BatchNormalization()(feat) \n",
    "    feat = tf.keras.layers.MaxPooling1D(pool_size=2,strides=2,padding=\"same\")(feat) # 高宽各减半的池化层\n",
    "    feat = tf.keras.layers.Dropout(rate=0.2)(feat)  #     \n",
    "\n",
    "\n",
    "    \n",
    "    cor1 = CorrelationLayer()(feat)  #\n",
    "    x = GraphConv(64, activation='relu',kernel_initializer=tf.keras.initializers.he_normal(seed=seed))([feat, cor1]) #包含了节点特征\n",
    "\n",
    "    cor2 = CorrelationLayer()(x)    \n",
    "    x = GraphConv(32, activation='relu',kernel_initializer=tf.keras.initializers.he_normal(seed=seed))([x, cor2]) #包含了节点特征\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    x = Self_Attention(4)(x) # 4\n",
    "    x = Flatten()(x)\n",
    "        \n",
    "    \n",
    "    inpt2 = tf.keras.layers.Input(shape=(9,))   #加入场地放大系数\n",
    "    conc = tf.keras.layers.Concatenate()([x,inpt2]) \n",
    "\n",
    "\n",
    "    \n",
    "    x = Dense(256, activation='relu')(conc)\n",
    "    x = Dense(128, activation='relu')(x)   \n",
    "    x = Dense(64, activation='relu')(x) #64\n",
    "    x = Dense(50, activation='relu')(x)  #50  正在调整\n",
    "    x = Dense(30, activation='relu')(x) #30\n",
    "\n",
    "\n",
    "    out = Dense(1)(x)\n",
    "\n",
    "    #model = Model([inp_seq, inp_lap, inp_feat], out)  ,inpt2\n",
    "    rms = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    model = Model([inp,inpt2], out)\n",
    "    model.compile(optimizer = rms, loss = 'mean_squared_error')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WQ.shape (None, 5, 4)\n",
      "K.permute_dimensions(WK, [0, 2, 1]).shape (None, 4, 5)\n",
      "QK.shape (None, 5, 5)\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 300, 9)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 150, 32)      1184        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 150, 32)      0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 150, 32)      128         re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 75, 32)       0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 75, 32)       0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 38, 64)       8256        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 38, 64)       0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 38, 64)       256         re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 19, 64)       0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 19, 64)       0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 10, 128)      32896       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 10, 128)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 10, 128)      512         re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 5, 128)       0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 5, 128)       0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "correlation_layer (CorrelationL (None, 5, 5)         0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv (GraphConv)          (None, 5, 64)        8256        dropout_2[0][0]                  \n",
      "                                                                 correlation_layer[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "correlation_layer_1 (Correlatio (None, 5, 5)         0           graph_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv_1 (GraphConv)        (None, 5, 32)        2080        graph_conv[0][0]                 \n",
      "                                                                 correlation_layer_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "self__attention (Self_Attention (None, 5, 4)         384         graph_conv_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 20)           0           self__attention[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 9)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 29)           0           flatten[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          7680        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          32896       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           8256        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 50)           3250        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 30)           1530        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            31          dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 107,595\n",
      "Trainable params: 107,147\n",
      "Non-trainable params: 448\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRAIN A MODEL FOR EACH STORES USING ALL THE DATA AVAILALBE FROM OTHER STORES ###\n",
    "\n",
    "\n",
    "tf.random.set_seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(33)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "session_conf = tf.compat.v1.ConfigProto(\n",
    "    intra_op_parallelism_threads=1, \n",
    "    inter_op_parallelism_threads=1\n",
    ")\n",
    "sess = tf.compat.v1.Session(\n",
    "    graph=tf.compat.v1.get_default_graph(), \n",
    "    config=session_conf\n",
    ")\n",
    "tf.compat.v1.keras.backend.set_session(sess)\n",
    "\n",
    "pred_train_all=np.zeros(train_y.shape)\n",
    "pred_test_all = np.zeros(test_y.shape)\n",
    "#pred_zhenli_all = np.zeros(y_zhenli.shape)\n",
    "\n",
    "    \n",
    "#es = EarlyStopping(patience=10, verbose=1, min_delta=0.001, monitor='val_loss', mode='auto', restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WQ.shape (None, 5, 4)\n",
      "K.permute_dimensions(WK, [0, 2, 1]).shape (None, 4, 5)\n",
      "QK.shape (None, 5, 5)\n",
      "Epoch 1/300\n",
      "WQ.shape (None, 5, 4)\n",
      "K.permute_dimensions(WK, [0, 2, 1]).shape (None, 4, 5)\n",
      "QK.shape (None, 5, 5)\n",
      "WQ.shape (None, 5, 4)\n",
      "K.permute_dimensions(WK, [0, 2, 1]).shape (None, 4, 5)\n",
      "QK.shape (None, 5, 5)\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.2153WQ.shape (None, 5, 4)\n",
      "K.permute_dimensions(WK, [0, 2, 1]).shape (None, 4, 5)\n",
      "QK.shape (None, 5, 5)\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 0.2153 - val_loss: 0.0577\n",
      "Epoch 2/300\n",
      "51/51 [==============================] - 4s 81ms/step - loss: 0.0604 - val_loss: 0.0551\n",
      "Epoch 3/300\n",
      "51/51 [==============================] - 4s 83ms/step - loss: 0.0575 - val_loss: 0.0545\n",
      "Epoch 4/300\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 0.0562 - val_loss: 0.0546\n",
      "Epoch 5/300\n",
      "51/51 [==============================] - 5s 88ms/step - loss: 0.0563 - val_loss: 0.0543\n",
      "Epoch 6/300\n",
      "51/51 [==============================] - 5s 103ms/step - loss: 0.0558 - val_loss: 0.0562\n",
      "Epoch 7/300\n",
      "51/51 [==============================] - 5s 97ms/step - loss: 0.0567 - val_loss: 0.0569\n",
      "Epoch 8/300\n",
      "51/51 [==============================] - 5s 95ms/step - loss: 0.0559 - val_loss: 0.0540\n",
      "Epoch 9/300\n",
      "51/51 [==============================] - 5s 97ms/step - loss: 0.0555 - val_loss: 0.0551\n",
      "Epoch 10/300\n",
      "51/51 [==============================] - 5s 94ms/step - loss: 0.0550 - val_loss: 0.0541\n",
      "Epoch 11/300\n",
      "51/51 [==============================] - 5s 94ms/step - loss: 0.0541 - val_loss: 0.0549\n",
      "Epoch 12/300\n",
      "51/51 [==============================] - 5s 102ms/step - loss: 0.0541 - val_loss: 0.0512\n",
      "Epoch 13/300\n",
      "51/51 [==============================] - 5s 99ms/step - loss: 0.0527 - val_loss: 0.0522\n",
      "Epoch 14/300\n",
      "51/51 [==============================] - 5s 97ms/step - loss: 0.0529 - val_loss: 0.0505\n",
      "Epoch 15/300\n",
      "51/51 [==============================] - 5s 97ms/step - loss: 0.0515 - val_loss: 0.0520\n",
      "Epoch 16/300\n",
      "51/51 [==============================] - 5s 95ms/step - loss: 0.0526 - val_loss: 0.0517\n",
      "Epoch 17/300\n",
      "51/51 [==============================] - 5s 99ms/step - loss: 0.0519 - val_loss: 0.0497\n",
      "Epoch 18/300\n",
      "51/51 [==============================] - 5s 95ms/step - loss: 0.0511 - val_loss: 0.0507\n",
      "Epoch 19/300\n",
      "51/51 [==============================] - 5s 96ms/step - loss: 0.0505 - val_loss: 0.0494\n",
      "Epoch 20/300\n",
      "51/51 [==============================] - 5s 97ms/step - loss: 0.0507 - val_loss: 0.0488\n",
      "Epoch 21/300\n",
      "51/51 [==============================] - 6s 108ms/step - loss: 0.0504 - val_loss: 0.0477\n",
      "Epoch 22/300\n",
      "51/51 [==============================] - 5s 99ms/step - loss: 0.0498 - val_loss: 0.0487\n",
      "Epoch 23/300\n",
      "51/51 [==============================] - 5s 108ms/step - loss: 0.0500 - val_loss: 0.0490\n",
      "Epoch 24/300\n",
      "51/51 [==============================] - 6s 115ms/step - loss: 0.0499 - val_loss: 0.0502\n",
      "Epoch 25/300\n",
      "51/51 [==============================] - 5s 105ms/step - loss: 0.0494 - val_loss: 0.0482\n",
      "Epoch 26/300\n",
      "51/51 [==============================] - 5s 99ms/step - loss: 0.0503 - val_loss: 0.0498\n",
      "Epoch 27/300\n",
      "51/51 [==============================] - 5s 93ms/step - loss: 0.0489 - val_loss: 0.0478\n",
      "Epoch 28/300\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 0.0485 - val_loss: 0.0476\n",
      "Epoch 29/300\n",
      "51/51 [==============================] - 5s 101ms/step - loss: 0.0483 - val_loss: 0.0477\n",
      "Epoch 30/300\n",
      "51/51 [==============================] - 5s 94ms/step - loss: 0.0480 - val_loss: 0.0474\n",
      "Epoch 31/300\n",
      "51/51 [==============================] - 5s 96ms/step - loss: 0.0478 - val_loss: 0.0474\n",
      "Epoch 32/300\n",
      "51/51 [==============================] - 5s 100ms/step - loss: 0.0478 - val_loss: 0.0474\n",
      "Epoch 33/300\n",
      "51/51 [==============================] - 5s 94ms/step - loss: 0.0482 - val_loss: 0.0474\n",
      "Epoch 34/300\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 0.0479 - val_loss: 0.0473\n",
      "Epoch 35/300\n",
      "51/51 [==============================] - 5s 97ms/step - loss: 0.0477 - val_loss: 0.0473\n",
      "Epoch 36/300\n",
      "51/51 [==============================] - 5s 99ms/step - loss: 0.0474 - val_loss: 0.0476\n",
      "Epoch 37/300\n",
      "51/51 [==============================] - 5s 102ms/step - loss: 0.0477 - val_loss: 0.0474\n",
      "Epoch 38/300\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 0.0476 - val_loss: 0.0480\n",
      "Epoch 39/300\n",
      "51/51 [==============================] - 5s 90ms/step - loss: 0.0478 - val_loss: 0.0472\n",
      "Epoch 40/300\n",
      "51/51 [==============================] - 5s 90ms/step - loss: 0.0476 - val_loss: 0.0474\n",
      "Epoch 41/300\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 0.0474 - val_loss: 0.0470\n",
      "Epoch 42/300\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 0.0475 - val_loss: 0.0472\n",
      "Epoch 43/300\n",
      "51/51 [==============================] - 5s 94ms/step - loss: 0.0477 - val_loss: 0.0471\n",
      "Epoch 44/300\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 0.0477 - val_loss: 0.0470\n",
      "Epoch 45/300\n",
      "51/51 [==============================] - 5s 92ms/step - loss: 0.0472 - val_loss: 0.0468\n",
      "Epoch 46/300\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 0.0473 - val_loss: 0.0470\n",
      "Epoch 47/300\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 0.0472 - val_loss: 0.0472\n",
      "Epoch 48/300\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 0.0474 - val_loss: 0.0471\n",
      "Epoch 49/300\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 0.0472 - val_loss: 0.0481\n",
      "Epoch 50/300\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 0.0471 - val_loss: 0.0468\n",
      "Epoch 51/300\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 0.0469 - val_loss: 0.0469\n",
      "Epoch 52/300\n",
      "51/51 [==============================] - 5s 90ms/step - loss: 0.0467 - val_loss: 0.0468\n",
      "Epoch 53/300\n",
      "51/51 [==============================] - 5s 90ms/step - loss: 0.0468 - val_loss: 0.0468\n",
      "Epoch 54/300\n",
      "51/51 [==============================] - 5s 94ms/step - loss: 0.0468 - val_loss: 0.0468\n",
      "Epoch 55/300\n",
      "51/51 [==============================] - 5s 92ms/step - loss: 0.0470 - val_loss: 0.0468\n",
      "Epoch 56/300\n",
      "51/51 [==============================] - 5s 95ms/step - loss: 0.0468 - val_loss: 0.0468\n",
      "Epoch 57/300\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 0.0468 - val_loss: 0.0468\n",
      "Epoch 58/300\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 0.0468 - val_loss: 0.0468\n",
      "Epoch 59/300\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 0.0467 - val_loss: 0.0468\n",
      "Epoch 60/300\n",
      "51/51 [==============================] - 5s 92ms/step - loss: 0.0465 - val_loss: 0.0468\n",
      "Epoch 61/300\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 0.0467 - val_loss: 0.0468\n",
      "Epoch 62/300\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 0.0468 - val_loss: 0.0468\n",
      "Epoch 63/300\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 0.0468 - val_loss: 0.0468\n",
      "Epoch 64/300\n",
      "51/51 [==============================] - 5s 90ms/step - loss: 0.0468 - val_loss: 0.0468\n",
      "Epoch 65/300\n",
      "51/51 [==============================] - 5s 90ms/step - loss: 0.0469 - val_loss: 0.0468\n",
      "Epoch 66/300\n",
      "51/51 [==============================] - 5s 90ms/step - loss: 0.0466 - val_loss: 0.0468\n",
      "Epoch 67/300\n",
      "51/51 [==============================] - 5s 90ms/step - loss: 0.0469 - val_loss: 0.0468\n",
      "Epoch 68/300\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 0.0469 - val_loss: 0.0468\n",
      "Epoch 69/300\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 0.0469 - val_loss: 0.0468\n",
      "Epoch 70/300\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 0.0468 - val_loss: 0.0468\n",
      "Epoch 71/300\n",
      "51/51 [==============================] - 5s 92ms/step - loss: 0.0468 - val_loss: 0.0468\n",
      "Epoch 72/300\n",
      "51/51 [==============================] - 5s 90ms/step - loss: 0.0467 - val_loss: 0.0468\n",
      "WQ.shape (None, 5, 4)\n",
      "K.permute_dimensions(WK, [0, 2, 1]).shape (None, 4, 5)\n",
      "QK.shape (None, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "lr_reducer = ReduceLROnPlateau(monitor=\"val_loss\",\n",
    "                               factor=0.1,\n",
    "                                cooldown= 0,\n",
    "                                patience= 5,\n",
    "                                min_lr=0.1e-7)\n",
    "early_stopping_monitor = EarlyStopping(monitor= 'val_loss', patience = 10) #10  17.20 1.32\n",
    "callbacks = [lr_reducer, early_stopping_monitor]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = get_model()\n",
    "model.fit([train_x,train_physics], train_y, epochs=300, batch_size=256,  \n",
    "            validation_split=0.1, callbacks=callbacks)  #256 ,train_physics  ,test_physics ,train_physics\n",
    "\n",
    "pred_train_all = model.predict([train_x,train_physics]).ravel()\n",
    "pred_test_all = model.predict([test_x,test_physics]).ravel()  ##ravel() 转换成1列\n",
    "\n",
    "\n",
    "#pred_valid_all = scaler_seq.inverse_transform(pred_valid_all)\n",
    "#reverse_valid = scaler_seq.inverse_transform(y_valid)\n",
    "#pred_test_all = scaler_seq.inverse_transform(pred_test_all)\n",
    "#reverse_test = scaler_seq.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练标准差STD= 0.2141215377932047\n",
      "训练误差均值MEAN= 0.0009667937801515101\n",
      "训练平均绝对误差MAE= 0.16791834608944836\n",
      "训练RMSE= 0.21412372039813835\n",
      "训练MAPE= 26.952647411585527\n",
      "训练r2 score: 0.7532414560532215\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score\n",
    "print(\"训练标准差STD=\",np.std(pred_train_all-train_y.ravel()))\n",
    "print(\"训练误差均值MEAN=\",np.mean(pred_train_all-train_y.ravel()))\n",
    "print(\"训练平均绝对误差MAE=\",metrics.mean_absolute_error(pred_train_all, train_y.ravel()))\n",
    "print(\"训练RMSE=\",metrics.mean_squared_error(pred_train_all, train_y.ravel())**0.5)\n",
    "print(\"训练MAPE=\",np.mean(np.abs((train_y.ravel() - pred_train_all) / train_y.ravel())) * 100)\n",
    "print(\"训练r2 score:\", r2_score(train_y.ravel(), pred_train_all))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.axis('equal')\n",
    "\n",
    "x3 = np.arange(-2, 5, 0.01)\n",
    "y3=x3\n",
    "plt.plot(x3, y3, \"black\")\n",
    "plt.plot(train_y.ravel(),pred_train_all,'.')\n",
    "plt.xlim(-2, 5)\n",
    "plt.ylim(-2, 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14453, 1)\n",
      "(14453, 1)\n",
      "(14453, 2)\n"
     ]
    }
   ],
   "source": [
    "#########################保存训练结果####################################\n",
    "pred_train_all=pred_train_all.reshape(pred_train_all.shape[0],1)\n",
    "\n",
    "#y_score_tr=y_score_tr.reshape(y_score_tr.shape[0],1)\n",
    "print(pred_train_all.shape)\n",
    "print(train_y.shape)\n",
    "\n",
    "tr_result=np.concatenate((train_y,pred_train_all),axis=1)\n",
    "\n",
    "print(tr_result.shape)\n",
    "\n",
    "data_tr = pd.DataFrame(tr_result) #将数组转换为dataframe结构\n",
    "data_tr.columns=['实际PGA','预测PGA']\n",
    "#writer_tr = pd.ExcelWriter(r'\\PGAtrain3.xls')   # 写入Excel文件\n",
    "\n",
    "data_tr.to_excel(writer_tr,float_format='%.5f',index=False)   ## ‘page_1’是写入excel的sheet名\n",
    "writer_tr.save()\n",
    "writer_tr.close()\n",
    "#########################保存训练结果####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试标准差STD= 0.2171916165434163\n",
      "测试误差均值MEAN= -0.005353617442194852\n",
      "测试平均绝对误差MAE= 0.1702813112377905\n",
      "测试RMSE= 0.21725758793759026\n",
      "测试MAPE= 65.54380820283174\n",
      "测试r2 score: 0.754913799644864\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"测试标准差STD=\",np.std(pred_test_all-test_y.ravel()))\n",
    "print(\"测试误差均值MEAN=\",np.mean(pred_test_all-test_y.ravel()))\n",
    "print(\"测试平均绝对误差MAE=\",metrics.mean_absolute_error(pred_test_all, test_y.ravel()))\n",
    "print(\"测试RMSE=\",metrics.mean_squared_error(pred_test_all, test_y.ravel())**0.5)\n",
    "print(\"测试MAPE=\",np.mean(np.abs((test_y.ravel() - pred_test_all) / test_y.ravel())) * 100)\n",
    "print(\"测试r2 score:\", r2_score(test_y.ravel(), pred_test_all))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.axis('equal')\n",
    "\n",
    "x3 = np.arange(-2, 5, 0.01)\n",
    "y3=x3\n",
    "plt.plot(x3, y3, \"black\")\n",
    "plt.plot(test_y.ravel(),pred_test_all,'.')\n",
    "plt.xlim(-2, 5)\n",
    "plt.ylim(-2, 5)\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3614, 1)\n",
      "(3614, 1)\n",
      "(3614, 2)\n"
     ]
    }
   ],
   "source": [
    "#########################保存测试结果####################################\n",
    "pred_test_all=pred_test_all.reshape(pred_test_all.shape[0],1)\n",
    "\n",
    "print(pred_test_all.shape)\n",
    "print(test_y.shape)\n",
    "\n",
    "te_result=np.concatenate((test_y,pred_test_all),axis=1)\n",
    "\n",
    "print(te_result.shape)\n",
    "\n",
    "data_te = pd.DataFrame(te_result) #将数组转换为dataframe结构\n",
    "data_te.columns=['实际PGA','预测PGA']\n",
    "writer_te = pd.ExcelWriter(r'\\PGAtest3.xls')   # 写入Excel文件\n",
    "\n",
    "data_te.to_excel(writer_te,float_format='%.5f',index=False)   ## ‘page_1’是写入excel的sheet名\n",
    "writer_te.save()\n",
    "writer_te.close()\n",
    "#########################保存测试结果####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
