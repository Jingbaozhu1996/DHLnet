{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date, timedelta\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras import layers,Sequential,losses,optimizers,datasets\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class CorrelationLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(CorrelationLayer, self).__init__()\n",
    "\n",
    "    def call(self, x):\n",
    "        # Compute mean and standard deviation for each batch and node\n",
    "        mean = tf.reduce_mean(x, axis=1, keepdims=True)\n",
    "        std = tf.math.reduce_std(x, axis=1, keepdims=True)\n",
    "\n",
    "        # Compute centered inputs\n",
    "        x_centered = x - mean\n",
    "\n",
    "        # Compute covariance matrix for each batch and node\n",
    "        covariance_matrix = tf.matmul(x_centered, x_centered, transpose_b=True)\n",
    "\n",
    "        # Compute correlation matrix using covariance matrix and standard deviation\n",
    "        correlation_matrix = tf.divide(covariance_matrix, tf.matmul(std, std, transpose_b=True))\n",
    "\n",
    "        # Compute Laplacian transformation of correlation matrix\n",
    "        laplacian_transform = self.localpooling_filter(correlation_matrix)\n",
    "\n",
    "        return laplacian_transform\n",
    "\n",
    "    def localpooling_filter(self, matrix):\n",
    "        # Compute diagonal degree matrix\n",
    "        degree_matrix = tf.linalg.diag(tf.reduce_sum(matrix, axis=1))\n",
    "\n",
    "        # Compute graph Laplacian\n",
    "        laplacian_matrix = degree_matrix - matrix\n",
    "\n",
    "        # Compute Laplacian eigenvectors and eigenvalues\n",
    "        eigenvalues, eigenvectors = tf.linalg.eigh(laplacian_matrix)\n",
    "\n",
    "        # Compute Laplacian Fourier Transform\n",
    "        laplacian_transform = tf.matmul(eigenvectors, tf.matmul(tf.linalg.diag(eigenvalues), eigenvectors, adjoint_b=True))\n",
    "\n",
    "        return laplacian_transform\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORT SPEKTRAL CLASSES ###\n",
    "\n",
    "from spektral_utilities import *\n",
    "from spektral_gcn import GraphConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as scio\n",
    "import pandas as pd\n",
    "\n",
    "#input\n",
    "feature1 = r'\\Traning and Test\\ACC_EW.mat'\n",
    "data1 = scio.loadmat(feature1)\n",
    "AA=data1['ACC_EW']\n",
    "A=AA[:,0:300]\n",
    "\n",
    "feature2 = r'\\Traning and Test\\ACC_NS.mat'\n",
    "data2 = scio.loadmat(feature2)\n",
    "BB=data2['ACC_NS']\n",
    "B=BB[:,0:300]\n",
    "\n",
    "feature3 = r'\\Traning and Test\\ACC_UD.mat'\n",
    "data3 = scio.loadmat(feature3)\n",
    "CC=data3['ACC_UD']\n",
    "C=CC[:,0:300]\n",
    "\n",
    "feature4 = r'\\Traning and Test\\DIS_EW.mat'\n",
    "data4 = scio.loadmat(feature4)\n",
    "DD=data4['DIS_EW']\n",
    "D=DD[:,0:300]\n",
    "\n",
    "feature5 = r'\\Traning and Test\\DIS_NS.mat'\n",
    "data5 = scio.loadmat(feature5)\n",
    "EE=data5['DIS_NS']\n",
    "E=EE[:,0:300]\n",
    "\n",
    "feature6 = r'\\Traning and Test\\DIS_UD.mat'\n",
    "data6 = scio.loadmat(feature6)\n",
    "FF=data6['DIS_UD']\n",
    "F=FF[:,0:300]\n",
    "\n",
    "feature7 = r'\\Traning and Test\\VEL_EW.mat'\n",
    "data7 = scio.loadmat(feature7)\n",
    "GG=data7['VEL_EW']\n",
    "G=GG[:,0:300]\n",
    "\n",
    "feature8 = r'\\Traning and Test\\VEL_NS.mat'\n",
    "data8 = scio.loadmat(feature8)\n",
    "HH=data8['VEL_NS']\n",
    "H=HH[:,0:300]\n",
    "\n",
    "feature9 = r'\\Traning and Test\\VEL_UD.mat'\n",
    "data9 = scio.loadmat(feature9)\n",
    "II=data9['VEL_UD']\n",
    "I=II[:,0:300]\n",
    "\n",
    "\n",
    "label = pd.read_csv(open(r'\\KnowledgeBase\\PGV\\Features3s.csv',encoding='UTF-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18067, 2700)\n",
      "[-3.11349585 -1.6162357  -1.1193538  -3.59711571 -1.39303892 -5.72870579\n",
      "  0.60858381  0.37864947 -0.95081472  1.30721834 -1.25808251]\n",
      "(18067, 11)\n"
     ]
    }
   ],
   "source": [
    "raw_data1=np.hstack((A,B))\n",
    "raw_data2=np.hstack((raw_data1,C))\n",
    "raw_data3=np.hstack((raw_data2,D))\n",
    "raw_data4=np.hstack((raw_data3,E))\n",
    "raw_data5=np.hstack((raw_data4,F))\n",
    "raw_data6=np.hstack((raw_data5,G))\n",
    "raw_data7=np.hstack((raw_data6,H))\n",
    "x_data=np.hstack((raw_data7,I))\n",
    "\n",
    "print(x_data.shape)\n",
    "\n",
    "\n",
    "y_data=label.iloc[:,[0,1,2,3,4,5,6,7,8,9,10]].values  #知识嵌入\n",
    "#y_data=label.iloc[:,[12]].values    #导入数据  iloc通过行号获取行数据\n",
    "print(y_data[0])\n",
    "print(y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练测试集\n",
    "#x_data_train_test=x_data[0:23432]\n",
    "#y_data_train_test=y_data[0:23432]\n",
    "#print(x_data_train_test.shape)\n",
    "#print(y_data_train_test.shape)\n",
    "#震例\n",
    "#x_data_zhenli=x_data[23432:27361]\n",
    "#y_data_zhenli=y_data[23432:27361]\n",
    "#print(x_data_zhenli.shape)\n",
    "#print(y_data_zhenli.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  #random_state=21  24  26  27  65\n",
    "train_xx, test_xx, train_y1, test_y1 = train_test_split(x_data, y_data, test_size=0.2, random_state=30)\n",
    "#print(train_xx.shape)   30 17.14  0.59\n",
    "#print(test_xx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14453, 1)\n",
      "[-0.90576334]\n",
      "(14453, 9)\n",
      "[-2.86703925 -1.73043704 -1.08644753 -2.9644417  -0.98313256 -4.61410526\n",
      "  1.02345287  0.52351466 -0.73253894]\n",
      "(3614, 1)\n",
      "[-0.42881059]\n",
      "(3614, 9)\n",
      "[-1.92127329 -1.0170204  -0.08808089 -1.37351168  0.35533502 -2.13072095\n",
      "  2.35732444  1.36126256  0.32020884]\n"
     ]
    }
   ],
   "source": [
    "train_y=train_y1[:,[10]]\n",
    "train_physics=train_y1[:,[0,1,2,3,4,5,6,7,8]]\n",
    "print(train_y.shape)\n",
    "print(train_y[0])\n",
    "\n",
    "print(train_physics.shape)\n",
    "print(train_physics[0])\n",
    "\n",
    "\n",
    "\n",
    "test_y=test_y1[:,[10]]\n",
    "test_physics=test_y1[:,[0,1,2,3,4,5,6,7,8]]\n",
    "print(test_y.shape)\n",
    "print(test_y[0])\n",
    "\n",
    "print(test_physics.shape)\n",
    "print(test_physics[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=[]\n",
    "for i in range(len(train_xx)):\n",
    "    train_x.append(np.array(train_xx[i].reshape(9,1,300)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x=[]\n",
    "for i in range(len(test_xx)):\n",
    "    test_x.append(np.array(test_xx[i].reshape(9,1,300)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=np.array(train_x)\n",
    "test_x=np.array(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 14453\n",
      "1 300\n",
      "(14453, 300, 9)\n"
     ]
    }
   ],
   "source": [
    "#3#  ##Reshaping\n",
    "train_x = np.reshape(train_x, (train_x.shape[0], 300, 9))\n",
    "test_x = np.reshape(test_x, (test_x.shape[0], 300, 9))\n",
    "print(\"0\",train_x.shape[0])\n",
    "print(\"1\",train_x.shape[1])\n",
    "print(train_x.shape)\n",
    "#print(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "class Self_Attention(Layer):\n",
    " \n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(Self_Attention, self).__init__(**kwargs)\n",
    " \n",
    "    def build(self, input_shape):\n",
    "        # 为该层创建一个可训练的权重\n",
    "        #inputs.shape = (batch_size, time_steps, seq_len)\n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "                                      shape=(3,input_shape[2], self.output_dim),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    " \n",
    "        super(Self_Attention, self).build(input_shape)  # 一定要在最后调用它\n",
    " \n",
    "    def call(self, x):\n",
    "        WQ = K.dot(x, self.kernel[0])\n",
    "        WK = K.dot(x, self.kernel[1])\n",
    "        WV = K.dot(x, self.kernel[2])\n",
    " \n",
    "        print(\"WQ.shape\",WQ.shape)\n",
    " \n",
    "        print(\"K.permute_dimensions(WK, [0, 2, 1]).shape\",K.permute_dimensions(WK, [0, 2, 1]).shape)\n",
    " \n",
    " \n",
    "        QK = K.batch_dot(WQ,K.permute_dimensions(WK, [0, 2, 1]))\n",
    " \n",
    "        QK = QK / (64**0.5)\n",
    " \n",
    "        QK = K.softmax(QK)\n",
    " \n",
    "        print(\"QK.shape\",QK.shape)\n",
    " \n",
    "        V = K.batch_dot(QK,WV)\n",
    " \n",
    "        return V\n",
    " \n",
    "    def compute_output_shape(self, input_shape):\n",
    " \n",
    "        return (input_shape[0],input_shape[1],self.output_dim)\n",
    "\n",
    "    def get_config(self):  #在有自定义网络层时，需要保存模型时，重写get_config函数\n",
    "        config = {\"output_dim\": self.output_dim}\n",
    "        base_config = super(Self_Attention, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=50\n",
    "#50 17.20 1.32\n",
    "\n",
    "def get_model():\n",
    "\n",
    "    #opt = Adam(lr=0.001)\n",
    "\n",
    "    #inp_seq = tf.keras.layers.Input((sequence_length, 10))  #sequence_length = 14; 表示输入的序列长度是14; 14*10\n",
    "#    inp_lap = tf.keras.layers.Input((9, 9))  #输入的领接矩阵 10表示节点数\n",
    "    \n",
    "    inp = tf.keras.layers.Input((300,9))  #如果我用CNN提取特征？？  \n",
    "\n",
    "    feat = tf.keras.layers.Conv1D(32,kernel_size=4,strides=2,    #   32  15.76 0.65  33.68 0.302\n",
    "                  kernel_initializer=keras.initializers.he_normal(seed=seed),\\\n",
    "                  bias_initializer=keras.initializers.he_normal(seed=seed),\\\n",
    "                  input_shape = (300,9),padding=\"same\")(inp)\n",
    "    feat = tf.keras.layers.ReLU()(feat)\n",
    "    feat = tf.keras.layers.BatchNormalization()(feat) \n",
    "    feat = tf.keras.layers.MaxPooling1D(pool_size=2,strides=2,padding=\"same\")(feat)\n",
    "    feat = tf.keras.layers.Dropout(rate=0.2)(feat)  # \n",
    "    \n",
    "    \n",
    "    feat = tf.keras.layers.Conv1D(64,kernel_size=4,strides=2,   # 32  \n",
    "                  kernel_initializer=keras.initializers.he_normal(seed=seed),\\\n",
    "                  bias_initializer=keras.initializers.he_normal(seed=seed),\\\n",
    "                  padding=\"same\")(feat) \n",
    "    feat = tf.keras.layers.ReLU()(feat)\n",
    "    feat = tf.keras.layers.BatchNormalization()(feat) \n",
    "    feat = tf.keras.layers.MaxPooling1D(pool_size=2,strides=2,padding=\"same\")(feat) # 高宽各减半的池化层\n",
    "    feat = tf.keras.layers.Dropout(rate=0.2)(feat)  # \n",
    "    \n",
    "    feat = tf.keras.layers.Conv1D(128,kernel_size=4,strides=2,   # 32  \n",
    "                  kernel_initializer=keras.initializers.he_normal(seed=seed),\\\n",
    "                  bias_initializer=keras.initializers.he_normal(seed=seed),\\\n",
    "                  padding=\"same\")(feat) \n",
    "    feat = tf.keras.layers.ReLU()(feat)\n",
    "    feat = tf.keras.layers.BatchNormalization()(feat) \n",
    "    feat = tf.keras.layers.MaxPooling1D(pool_size=2,strides=2,padding=\"same\")(feat) # 高宽各减半的池化层\n",
    "    feat = tf.keras.layers.Dropout(rate=0.2)(feat)  #     \n",
    "\n",
    "\n",
    "    \n",
    "    cor1 = CorrelationLayer()(feat)  #\n",
    "    x = GraphConv(64, activation='relu',kernel_initializer=tf.keras.initializers.he_normal(seed=seed))([feat, cor1]) #包含了节点特征\n",
    "\n",
    "    cor2 = CorrelationLayer()(x)    \n",
    "    x = GraphConv(32, activation='relu',kernel_initializer=tf.keras.initializers.he_normal(seed=seed))([x, cor2]) #包含了节点特征\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    x = Self_Attention(8)(x) # 8\n",
    "    x = Flatten()(x)\n",
    "        \n",
    "    \n",
    "    inpt2 = tf.keras.layers.Input(shape=(9,))   #加入场地放大系数\n",
    "    conc = tf.keras.layers.Concatenate()([x,inpt2]) \n",
    "\n",
    "\n",
    "    \n",
    "    x = Dense(256, activation='relu')(conc)\n",
    "    x = Dense(128, activation='relu')(x)   \n",
    "    x = Dense(64, activation='relu')(x) #64\n",
    "    x = Dense(50, activation='relu')(x)  #50  正在调整\n",
    "    x = Dense(30, activation='relu')(x) #30\n",
    "\n",
    "\n",
    "    out = Dense(1)(x)\n",
    "\n",
    "    #model = Model([inp_seq, inp_lap, inp_feat], out)  ,inpt2\n",
    "    rms = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    model = Model([inp,inpt2], out)\n",
    "    model.compile(optimizer = rms, loss = 'mean_squared_error')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WQ.shape (None, 5, 8)\n",
      "K.permute_dimensions(WK, [0, 2, 1]).shape (None, 8, 5)\n",
      "QK.shape (None, 5, 5)\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 300, 9)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 150, 32)      1184        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 150, 32)      0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 150, 32)      128         re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 75, 32)       0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 75, 32)       0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 38, 64)       8256        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 38, 64)       0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 38, 64)       256         re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 19, 64)       0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 19, 64)       0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 10, 128)      32896       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 10, 128)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 10, 128)      512         re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 5, 128)       0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 5, 128)       0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "correlation_layer (CorrelationL (None, 5, 5)         0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv (GraphConv)          (None, 5, 64)        8256        dropout_2[0][0]                  \n",
      "                                                                 correlation_layer[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "correlation_layer_1 (Correlatio (None, 5, 5)         0           graph_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv_1 (GraphConv)        (None, 5, 32)        2080        graph_conv[0][0]                 \n",
      "                                                                 correlation_layer_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "self__attention (Self_Attention (None, 5, 8)         768         graph_conv_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 40)           0           self__attention[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 9)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 49)           0           flatten[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          12800       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          32896       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           8256        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 50)           3250        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 30)           1530        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            31          dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 113,099\n",
      "Trainable params: 112,651\n",
      "Non-trainable params: 448\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRAIN A MODEL FOR EACH STORES USING ALL THE DATA AVAILALBE FROM OTHER STORES ###\n",
    "\n",
    "\n",
    "tf.random.set_seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(33)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "session_conf = tf.compat.v1.ConfigProto(\n",
    "    intra_op_parallelism_threads=1, \n",
    "    inter_op_parallelism_threads=1\n",
    ")\n",
    "sess = tf.compat.v1.Session(\n",
    "    graph=tf.compat.v1.get_default_graph(), \n",
    "    config=session_conf\n",
    ")\n",
    "tf.compat.v1.keras.backend.set_session(sess)\n",
    "\n",
    "pred_train_all=np.zeros(train_y.shape)\n",
    "pred_test_all = np.zeros(test_y.shape)\n",
    "#pred_zhenli_all = np.zeros(y_zhenli.shape)\n",
    "\n",
    "    \n",
    "#es = EarlyStopping(patience=10, verbose=1, min_delta=0.001, monitor='val_loss', mode='auto', restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WQ.shape (None, 5, 8)\n",
      "K.permute_dimensions(WK, [0, 2, 1]).shape (None, 8, 5)\n",
      "QK.shape (None, 5, 5)\n",
      "Epoch 1/300\n",
      "WQ.shape (None, 5, 8)\n",
      "K.permute_dimensions(WK, [0, 2, 1]).shape (None, 8, 5)\n",
      "QK.shape (None, 5, 5)\n",
      "WQ.shape (None, 5, 8)\n",
      "K.permute_dimensions(WK, [0, 2, 1]).shape (None, 8, 5)\n",
      "QK.shape (None, 5, 5)\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.0984WQ.shape (None, 5, 8)\n",
      "K.permute_dimensions(WK, [0, 2, 1]).shape (None, 8, 5)\n",
      "QK.shape (None, 5, 5)\n",
      "51/51 [==============================] - 4s 87ms/step - loss: 0.0984 - val_loss: 0.0747\n",
      "Epoch 2/300\n",
      "51/51 [==============================] - 4s 80ms/step - loss: 0.0743 - val_loss: 0.0699\n",
      "Epoch 3/300\n",
      "51/51 [==============================] - 4s 79ms/step - loss: 0.0708 - val_loss: 0.0700\n",
      "Epoch 4/300\n",
      "51/51 [==============================] - 4s 80ms/step - loss: 0.0694 - val_loss: 0.0707\n",
      "Epoch 5/300\n",
      "51/51 [==============================] - 4s 84ms/step - loss: 0.0696 - val_loss: 0.0695\n",
      "Epoch 6/300\n",
      "51/51 [==============================] - 4s 85ms/step - loss: 0.0688 - val_loss: 0.0698\n",
      "Epoch 7/300\n",
      "51/51 [==============================] - 4s 82ms/step - loss: 0.0689 - val_loss: 0.0690\n",
      "Epoch 8/300\n",
      "51/51 [==============================] - 4s 88ms/step - loss: 0.0686 - val_loss: 0.0691\n",
      "Epoch 9/300\n",
      "51/51 [==============================] - 4s 88ms/step - loss: 0.0678 - val_loss: 0.0690\n",
      "Epoch 10/300\n",
      "51/51 [==============================] - 5s 99ms/step - loss: 0.0676 - val_loss: 0.0686\n",
      "Epoch 11/300\n",
      "51/51 [==============================] - 5s 96ms/step - loss: 0.0669 - val_loss: 0.0662\n",
      "Epoch 12/300\n",
      "51/51 [==============================] - 5s 106ms/step - loss: 0.0667 - val_loss: 0.0648\n",
      "Epoch 13/300\n",
      "51/51 [==============================] - 5s 101ms/step - loss: 0.0645 - val_loss: 0.0663\n",
      "Epoch 14/300\n",
      "51/51 [==============================] - 5s 99ms/step - loss: 0.0659 - val_loss: 0.0661\n",
      "Epoch 15/300\n",
      "51/51 [==============================] - 5s 102ms/step - loss: 0.0648 - val_loss: 0.0639\n",
      "Epoch 16/300\n",
      "51/51 [==============================] - 5s 97ms/step - loss: 0.0634 - val_loss: 0.0632\n",
      "Epoch 17/300\n",
      "51/51 [==============================] - 5s 93ms/step - loss: 0.0631 - val_loss: 0.0622\n",
      "Epoch 18/300\n",
      "51/51 [==============================] - 5s 99ms/step - loss: 0.0644 - val_loss: 0.0635\n",
      "Epoch 19/300\n",
      "51/51 [==============================] - 6s 118ms/step - loss: 0.0623 - val_loss: 0.0614\n",
      "Epoch 20/300\n",
      "51/51 [==============================] - 6s 109ms/step - loss: 0.0622 - val_loss: 0.0593\n",
      "Epoch 21/300\n",
      "51/51 [==============================] - 5s 101ms/step - loss: 0.0602 - val_loss: 0.0603\n",
      "Epoch 22/300\n",
      "51/51 [==============================] - 5s 100ms/step - loss: 0.0600 - val_loss: 0.0588\n",
      "Epoch 23/300\n",
      "51/51 [==============================] - 5s 106ms/step - loss: 0.0600 - val_loss: 0.0602\n",
      "Epoch 24/300\n",
      "51/51 [==============================] - 5s 94ms/step - loss: 0.0604 - val_loss: 0.0621\n",
      "Epoch 25/300\n",
      "51/51 [==============================] - 5s 92ms/step - loss: 0.0602 - val_loss: 0.0591\n",
      "Epoch 26/300\n",
      "51/51 [==============================] - 5s 92ms/step - loss: 0.0640 - val_loss: 0.0591\n",
      "Epoch 27/300\n",
      "51/51 [==============================] - 5s 92ms/step - loss: 0.0597 - val_loss: 0.0604\n",
      "Epoch 28/300\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 0.0588 - val_loss: 0.0580\n",
      "Epoch 29/300\n",
      "51/51 [==============================] - 5s 92ms/step - loss: 0.0581 - val_loss: 0.0571\n",
      "Epoch 30/300\n",
      "51/51 [==============================] - 5s 92ms/step - loss: 0.0575 - val_loss: 0.0569\n",
      "Epoch 31/300\n",
      "51/51 [==============================] - 5s 92ms/step - loss: 0.0576 - val_loss: 0.0574\n",
      "Epoch 32/300\n",
      "51/51 [==============================] - 5s 92ms/step - loss: 0.0575 - val_loss: 0.0570\n",
      "Epoch 33/300\n",
      "51/51 [==============================] - 5s 92ms/step - loss: 0.0572 - val_loss: 0.0569\n",
      "Epoch 34/300\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 0.0573 - val_loss: 0.0571\n",
      "Epoch 35/300\n",
      "51/51 [==============================] - 5s 97ms/step - loss: 0.0571 - val_loss: 0.0568\n",
      "Epoch 36/300\n",
      "51/51 [==============================] - 5s 96ms/step - loss: 0.0565 - val_loss: 0.0575\n",
      "Epoch 37/300\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 0.0576 - val_loss: 0.0568\n",
      "Epoch 38/300\n",
      "51/51 [==============================] - 5s 94ms/step - loss: 0.0571 - val_loss: 0.0567\n",
      "Epoch 39/300\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 0.0573 - val_loss: 0.0565\n",
      "Epoch 40/300\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 0.0570 - val_loss: 0.0566\n",
      "Epoch 41/300\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 0.0569 - val_loss: 0.0564\n",
      "Epoch 42/300\n",
      "51/51 [==============================] - 5s 96ms/step - loss: 0.0564 - val_loss: 0.0564\n",
      "Epoch 43/300\n",
      "51/51 [==============================] - 5s 99ms/step - loss: 0.0565 - val_loss: 0.0568\n",
      "Epoch 44/300\n",
      "51/51 [==============================] - 5s 94ms/step - loss: 0.0566 - val_loss: 0.0561\n",
      "Epoch 45/300\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 0.0564 - val_loss: 0.0561\n",
      "Epoch 46/300\n",
      "51/51 [==============================] - 5s 92ms/step - loss: 0.0561 - val_loss: 0.0561\n",
      "Epoch 47/300\n",
      "51/51 [==============================] - 5s 92ms/step - loss: 0.0565 - val_loss: 0.0562\n",
      "Epoch 48/300\n",
      "51/51 [==============================] - 5s 92ms/step - loss: 0.0564 - val_loss: 0.0561\n",
      "Epoch 49/300\n",
      "51/51 [==============================] - 5s 92ms/step - loss: 0.0562 - val_loss: 0.0561\n",
      "Epoch 50/300\n",
      "51/51 [==============================] - 5s 102ms/step - loss: 0.0557 - val_loss: 0.0558\n",
      "Epoch 51/300\n",
      "51/51 [==============================] - 5s 94ms/step - loss: 0.0557 - val_loss: 0.0560\n",
      "Epoch 52/300\n",
      "51/51 [==============================] - 5s 102ms/step - loss: 0.0558 - val_loss: 0.0559\n",
      "Epoch 53/300\n",
      "51/51 [==============================] - 5s 95ms/step - loss: 0.0560 - val_loss: 0.0559\n",
      "Epoch 54/300\n",
      "51/51 [==============================] - 5s 96ms/step - loss: 0.0558 - val_loss: 0.0558\n",
      "Epoch 55/300\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 0.0557 - val_loss: 0.0559\n",
      "Epoch 56/300\n",
      "51/51 [==============================] - 4s 88ms/step - loss: 0.0560 - val_loss: 0.0559\n",
      "Epoch 57/300\n",
      "51/51 [==============================] - 4s 88ms/step - loss: 0.0558 - val_loss: 0.0559\n",
      "Epoch 58/300\n",
      "51/51 [==============================] - 5s 97ms/step - loss: 0.0557 - val_loss: 0.0559\n",
      "Epoch 59/300\n",
      "51/51 [==============================] - 5s 98ms/step - loss: 0.0557 - val_loss: 0.0559\n",
      "Epoch 60/300\n",
      "51/51 [==============================] - 5s 92ms/step - loss: 0.0558 - val_loss: 0.0558\n",
      "Epoch 61/300\n",
      "51/51 [==============================] - 5s 92ms/step - loss: 0.0557 - val_loss: 0.0558\n",
      "Epoch 62/300\n",
      "51/51 [==============================] - 5s 99ms/step - loss: 0.0558 - val_loss: 0.0559\n",
      "Epoch 63/300\n",
      "51/51 [==============================] - 5s 94ms/step - loss: 0.0557 - val_loss: 0.0559\n",
      "Epoch 64/300\n",
      "51/51 [==============================] - 5s 92ms/step - loss: 0.0561 - val_loss: 0.0558\n",
      "Epoch 65/300\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 0.0561 - val_loss: 0.0559\n",
      "Epoch 66/300\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 0.0556 - val_loss: 0.0558\n",
      "Epoch 67/300\n",
      "51/51 [==============================] - 5s 92ms/step - loss: 0.0557 - val_loss: 0.0558\n",
      "Epoch 68/300\n",
      "51/51 [==============================] - 5s 90ms/step - loss: 0.0554 - val_loss: 0.0558\n",
      "Epoch 69/300\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 0.0555 - val_loss: 0.0558\n",
      "Epoch 70/300\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 0.0558 - val_loss: 0.0558\n",
      "Epoch 71/300\n",
      "51/51 [==============================] - 5s 92ms/step - loss: 0.0561 - val_loss: 0.0558\n",
      "Epoch 72/300\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 0.0562 - val_loss: 0.0558\n",
      "Epoch 73/300\n",
      "51/51 [==============================] - 5s 90ms/step - loss: 0.0559 - val_loss: 0.0558\n",
      "Epoch 74/300\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 0.0560 - val_loss: 0.0558\n",
      "Epoch 75/300\n",
      "51/51 [==============================] - 5s 91ms/step - loss: 0.0561 - val_loss: 0.0558\n",
      "Epoch 76/300\n",
      "51/51 [==============================] - 5s 96ms/step - loss: 0.0557 - val_loss: 0.0559\n",
      "Epoch 77/300\n",
      "51/51 [==============================] - 5s 98ms/step - loss: 0.0557 - val_loss: 0.0559\n",
      "Epoch 78/300\n",
      "51/51 [==============================] - 5s 103ms/step - loss: 0.0560 - val_loss: 0.0559\n",
      "Epoch 79/300\n",
      "51/51 [==============================] - 6s 110ms/step - loss: 0.0561 - val_loss: 0.0559\n",
      "Epoch 80/300\n",
      "51/51 [==============================] - 5s 101ms/step - loss: 0.0556 - val_loss: 0.0559\n",
      "Epoch 81/300\n",
      "51/51 [==============================] - 5s 97ms/step - loss: 0.0559 - val_loss: 0.0558\n",
      "WQ.shape (None, 5, 8)\n",
      "K.permute_dimensions(WK, [0, 2, 1]).shape (None, 8, 5)\n",
      "QK.shape (None, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "lr_reducer = ReduceLROnPlateau(monitor=\"val_loss\",\n",
    "                               factor=0.1,\n",
    "                                cooldown= 0,\n",
    "                                patience= 5,\n",
    "                                min_lr=0.1e-7)\n",
    "early_stopping_monitor = EarlyStopping(monitor= 'val_loss', patience = 10) #10  17.20 1.32\n",
    "callbacks = [lr_reducer, early_stopping_monitor]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = get_model()\n",
    "model.fit([train_x,train_physics], train_y, epochs=300, batch_size=256,  \n",
    "            validation_split=0.1, callbacks=callbacks)  #256 ,train_physics  ,test_physics ,train_physics\n",
    "\n",
    "pred_train_all = model.predict([train_x,train_physics]).ravel()\n",
    "pred_test_all = model.predict([test_x,test_physics]).ravel()  ##ravel() 转换成1列\n",
    "\n",
    "\n",
    "#pred_valid_all = scaler_seq.inverse_transform(pred_valid_all)\n",
    "#reverse_valid = scaler_seq.inverse_transform(y_valid)\n",
    "#pred_test_all = scaler_seq.inverse_transform(pred_test_all)\n",
    "#reverse_test = scaler_seq.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练标准差STD= 0.23162216474090142\n",
      "训练误差均值MEAN= 0.002699661792495581\n",
      "训练平均绝对误差MAE= 0.18158900514183407\n",
      "训练RMSE= 0.23163789710031288\n",
      "训练MAPE= 85.22666654784418\n",
      "训练r2 score: 0.7798611541782219\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score\n",
    "print(\"训练标准差STD=\",np.std(pred_train_all-train_y.ravel()))\n",
    "print(\"训练误差均值MEAN=\",np.mean(pred_train_all-train_y.ravel()))\n",
    "print(\"训练平均绝对误差MAE=\",metrics.mean_absolute_error(pred_train_all, train_y.ravel()))\n",
    "print(\"训练RMSE=\",metrics.mean_squared_error(pred_train_all, train_y.ravel())**0.5)\n",
    "print(\"训练MAPE=\",np.mean(np.abs((train_y.ravel() - pred_train_all) / train_y.ravel())) * 100)\n",
    "print(\"训练r2 score:\", r2_score(train_y.ravel(), pred_train_all))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.axis('equal')\n",
    "\n",
    "x3 = np.arange(-3, 3, 0.01)\n",
    "y3=x3\n",
    "plt.plot(x3, y3, \"black\")\n",
    "plt.plot(train_y.ravel(),pred_train_all,'.')\n",
    "plt.xlim(-3, 3)\n",
    "plt.ylim(-3, 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14453, 1)\n",
      "(14453, 1)\n",
      "(14453, 2)\n"
     ]
    }
   ],
   "source": [
    "#########################保存训练结果####################################\n",
    "pred_train_all=pred_train_all.reshape(pred_train_all.shape[0],1)\n",
    "\n",
    "#y_score_tr=y_score_tr.reshape(y_score_tr.shape[0],1)\n",
    "print(pred_train_all.shape)\n",
    "print(train_y.shape)\n",
    "\n",
    "tr_result=np.concatenate((train_y,pred_train_all),axis=1)\n",
    "\n",
    "print(tr_result.shape)\n",
    "\n",
    "data_tr = pd.DataFrame(tr_result) #将数组转换为dataframe结构\n",
    "data_tr.columns=['实际PGV','预测PGV']\n",
    "#writer_tr = pd.ExcelWriter(r'\\PGVtrain3.xls')   # 写入Excel文件\n",
    "\n",
    "data_tr.to_excel(writer_tr,float_format='%.5f',index=False)   ## ‘page_1’是写入excel的sheet名\n",
    "writer_tr.save()\n",
    "writer_tr.close()\n",
    "#########################保存训练结果####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试标准差STD= 0.23544905402690414\n",
      "测试误差均值MEAN= -0.004972379635701108\n",
      "测试平均绝对误差MAE= 0.1832167951928826\n",
      "测试RMSE= 0.23550155328873215\n",
      "测试MAPE= 243.72069669537288\n",
      "测试r2 score: 0.7796125309400385\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"测试标准差STD=\",np.std(pred_test_all-test_y.ravel()))\n",
    "print(\"测试误差均值MEAN=\",np.mean(pred_test_all-test_y.ravel()))\n",
    "print(\"测试平均绝对误差MAE=\",metrics.mean_absolute_error(pred_test_all, test_y.ravel()))\n",
    "print(\"测试RMSE=\",metrics.mean_squared_error(pred_test_all, test_y.ravel())**0.5)\n",
    "print(\"测试MAPE=\",np.mean(np.abs((test_y.ravel() - pred_test_all) / test_y.ravel())) * 100)\n",
    "print(\"测试r2 score:\", r2_score(test_y.ravel(), pred_test_all))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.axis('equal')\n",
    "\n",
    "x3 = np.arange(-3, 3, 0.01)\n",
    "y3=x3\n",
    "plt.plot(x3, y3, \"black\")\n",
    "plt.plot(test_y.ravel(),pred_test_all,'.')\n",
    "plt.xlim(-3, 3)\n",
    "plt.ylim(-3, 3)\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3614, 1)\n",
      "(3614, 1)\n",
      "(3614, 2)\n"
     ]
    }
   ],
   "source": [
    "#########################保存测试结果####################################\n",
    "pred_test_all=pred_test_all.reshape(pred_test_all.shape[0],1)\n",
    "\n",
    "print(pred_test_all.shape)\n",
    "print(test_y.shape)\n",
    "\n",
    "te_result=np.concatenate((test_y,pred_test_all),axis=1)\n",
    "\n",
    "print(te_result.shape)\n",
    "\n",
    "data_te = pd.DataFrame(te_result) #将数组转换为dataframe结构\n",
    "data_te.columns=['实际PGV','预测PGV']\n",
    "writer_te = pd.ExcelWriter(r'\\PGVtest3.xls')   # 写入Excel文件\n",
    "\n",
    "data_te.to_excel(writer_te,float_format='%.5f',index=False)   ## ‘page_1’是写入excel的sheet名\n",
    "writer_te.save()\n",
    "writer_te.close()\n",
    "#########################保存测试结果####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
